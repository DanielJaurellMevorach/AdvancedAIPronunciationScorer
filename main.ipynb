{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d98b6b4a",
   "metadata": {},
   "source": [
    "Install all of the libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf471510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "from textgrid import TextGrid\n",
    "from librosa.feature import mfcc as librosa_mfcc\n",
    "import scipy.spatial\n",
    "import scipy.signal\n",
    "import wave\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d7c4d",
   "metadata": {},
   "source": [
    "The montreal forced aligner expects a .WAV audio file that is single channel (mono) and 16kHz sample rate. MP3 files from development and WEBM from the Front-End need to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Audio Preprocessing ------------------\n",
    "\n",
    "def convert_mp3_to_wav(input_file: str, output_file: str) -> str:\n",
    "    audio = AudioSegment.from_mp3(input_file)\n",
    "    audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "    audio.export(output_file, format=\"wav\")\n",
    "    return output_file\n",
    "\n",
    "def convert_webm_to_wav(input_file: str, output_file: str) -> str:\n",
    "    \"\"\"Convert WebM audio to WAV with robust error handling and fallbacks.\"\"\"\n",
    "\n",
    "    \n",
    "    # Verify input file\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "    \n",
    "    if os.path.getsize(input_file) == 0:\n",
    "        raise ValueError(f\"Input file is empty: {input_file}\")\n",
    "    \n",
    "    try:\n",
    "        try:\n",
    "            print(f\"Attempting to convert {input_file} with pydub...\")\n",
    "            audio = AudioSegment.from_file(input_file, format=\"webm\")\n",
    "            audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "            audio.export(output_file, format=\"wav\")\n",
    "            print(\"Pydub conversion successful\")\n",
    "            return output_file\n",
    "        except Exception as e:\n",
    "            print(f\"Pydub conversion failed: {e}\")\n",
    "        \n",
    "        print(\"Attempting direct FFmpeg conversion...\")\n",
    "        try:\n",
    "            cmd = [\n",
    "                \"ffmpeg\", \"-y\", \n",
    "                \"-i\", input_file, \n",
    "                \"-ar\", \"16000\", \n",
    "                \"-ac\", \"1\",\n",
    "                \"-vn\",  \n",
    "                \"-acodec\", \"pcm_s16le\",  \n",
    "                output_file\n",
    "            ]\n",
    "            result = subprocess.run(\n",
    "                cmd, \n",
    "                stderr=subprocess.PIPE, \n",
    "                stdout=subprocess.PIPE,\n",
    "                text=True\n",
    "            )\n",
    "            if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
    "                print(\"FFmpeg conversion successful\")\n",
    "                return output_file\n",
    "            else:\n",
    "                print(f\"FFmpeg conversion produced empty file: {result.stderr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"FFmpeg command failed: {e}\")\n",
    "        \n",
    "        print(\"Attempting FFmpeg conversion with explicit format...\")\n",
    "        try:\n",
    "            cmd = [\n",
    "                \"ffmpeg\", \"-y\", \n",
    "                \"-f\", \"webm\",\n",
    "                \"-i\", input_file,\n",
    "                \"-ar\", \"16000\", \n",
    "                \"-ac\", \"1\",\n",
    "                \"-acodec\", \"pcm_s16le\",\n",
    "                output_file\n",
    "            ]\n",
    "            result = subprocess.run(\n",
    "                cmd, \n",
    "                stderr=subprocess.PIPE, \n",
    "                stdout=subprocess.PIPE,\n",
    "                text=True\n",
    "            )\n",
    "            if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
    "                print(\"FFmpeg explicit format conversion successful\")\n",
    "                return output_file\n",
    "            else:\n",
    "                print(f\"FFmpeg explicit format produced empty file: {result.stderr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"FFmpeg explicit format command failed: {e}\")\n",
    "        \n",
    "        print(\"Creating minimal valid WAV file as fallback\")\n",
    "        with wave.open(output_file, 'wb') as wf:\n",
    "            wf.setnchannels(1)\n",
    "            wf.setsampwidth(2)  \n",
    "            wf.setframerate(16000)\n",
    "            wf.writeframes(b'\\x00' * 32000) \n",
    "        \n",
    "        return output_file\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Fatal error in webm to wav conversion: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9fe53",
   "metadata": {},
   "source": [
    "Montreal forced aligner can easily be ran in the terminal once installed, and when provided a corpus (folder containing .WAV files and a .TXT file with the transcript) it will output a folder with the aligned phonemes in .TextGrid format.\n",
    "\n",
    "The command I've been running in the miniconda terminal until making the process callable in python is:\n",
    "    \n",
    "mfa align --clean ./input_english ./model/pretrained_models/dictionary/english_us_arpa.dict english_us_arpa ./output_english\n",
    "\n",
    "./input_english --> folder containing the .WAV files and .TXT file with the transcript\n",
    "\n",
    "./model/pretrained_models/dictionary/english_us_arpa.dict --> path to the dictionary file\n",
    "\n",
    "english_us_arpa --> name of the model to use (in this case, no relative path was needed as MFA knows my environment variable folder)\n",
    "\n",
    "./output_english --> folder where the aligned phonemes will be saved in .TextGrid format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Forced Alignment ------------------\n",
    "\n",
    "def run_mfa_alignment(wav_path: str, transcript: str) -> str:\n",
    "    import time\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    timestamp = str(int(time.time()))\n",
    "    base_dir = os.path.join(\".\", \"audio\", timestamp) \n",
    "    \n",
    "    corpus_dir = os.path.join(base_dir, timestamp + \"-corpus\")\n",
    "    os.makedirs(corpus_dir, exist_ok=True)\n",
    "\n",
    "    shutil.copy(wav_path, os.path.join(corpus_dir, os.path.basename(wav_path)))\n",
    "    shutil.copy(transcript, os.path.join(corpus_dir, os.path.basename(transcript)))\n",
    "\n",
    "    aligned_output_dir = base_dir\n",
    "\n",
    "    lexicon_path = \"model/pretrained_models/dictionary/english_us_arpa.dict\"\n",
    "\n",
    "    mfa_align_command = [\n",
    "        \"mfa\", \"align\", \"--clean\",\n",
    "        corpus_dir,\n",
    "        lexicon_path,\n",
    "        \"english_us_arpa\",\n",
    "        aligned_output_dir,\n",
    "        \"--debug\",\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            mfa_align_command,\n",
    "            check=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            encoding='utf-8',\n",
    "            errors='replace'\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError(f\"Error running MFA alignment: {e}\")\n",
    "\n",
    "    textgrid_path = os.path.join(aligned_output_dir, os.path.splitext(os.path.basename(wav_path))[0] + \".TextGrid\")\n",
    "    if not os.path.exists(textgrid_path):\n",
    "        raise FileNotFoundError(f\"Expected TextGrid file not found: {textgrid_path}\")\n",
    "\n",
    "    return textgrid_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee86032",
   "metadata": {},
   "source": [
    "The Pronunciation Scoring Model analyzes phoneme segments from audio recordings and calculates quality scores using acoustic features such as energy, spectral characteristics, and duration. This is what Montreal Forced Aligner captures from audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ac0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Pronunciation Scoring Model ------------------\n",
    "\n",
    "def score_phonemes_with_mfa(audio_path: str, phoneme_intervals: list) -> list:\n",
    "    \"\"\"Score phonemes using MFA alignment metrics and acoustic features.\n",
    "       Enhanced to better differentiate native vs. non-native pronunciation.\"\"\"\n",
    "    \n",
    "    waveform, sr = librosa.load(audio_path, sr=16000)\n",
    "    \n",
    "    \n",
    "    vowels = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW']\n",
    "    stops = ['P', 'B', 'T', 'D', 'K', 'G']\n",
    "    fricatives = ['F', 'V', 'TH', 'DH', 'S', 'Z', 'SH', 'ZH', 'HH']\n",
    "    \n",
    "    results = []\n",
    "    for interval in phoneme_intervals:\n",
    "        phoneme = interval['phoneme']\n",
    "        start, end = interval['start'], interval['end']\n",
    "        start_idx, end_idx = int(start * sr), int(end * sr)\n",
    "        \n",
    "        if start_idx >= end_idx or end_idx > len(waveform):\n",
    "            continue\n",
    "            \n",
    "        segment = waveform[start_idx:end_idx]\n",
    "        if len(segment) == 0:\n",
    "            continue\n",
    "        \n",
    "        energy = np.mean(segment**2)\n",
    "        \n",
    "        spec = np.abs(librosa.stft(segment))\n",
    "        if spec.shape[1] > 1: \n",
    "            flux = np.mean(np.diff(spec, axis=1)**2)\n",
    "        else:\n",
    "            flux = 0\n",
    "            \n",
    "        \n",
    "        if phoneme in vowels and len(segment) > sr * 0.03:  \n",
    "            S = np.abs(librosa.stft(segment))\n",
    "            freqs = librosa.fft_frequencies(sr=sr)\n",
    "            if S.shape[1] > 0:\n",
    "              \n",
    "                frame_peaks = []\n",
    "                for frame in range(S.shape[1]):\n",
    "                    spectrum = S[:, frame]\n",
    "                    peaks, _ = scipy.signal.find_peaks(spectrum, height=np.max(spectrum)*0.1)\n",
    "                    if len(peaks) >= 2:\n",
    "                        formant_freqs = freqs[peaks]\n",
    "                        frame_peaks.append(formant_freqs[:3] if len(formant_freqs) >= 3 else formant_freqs)\n",
    "                \n",
    "        \n",
    "       \n",
    "        duration_score = 0.5 \n",
    "        \n",
    "        if phoneme in vowels:\n",
    "            \n",
    "                spectral_centroid = librosa.feature.spectral_centroid(y=segment, sr=sr)[0].mean()\n",
    "                zero_crossing_rate = librosa.feature.zero_crossing_rate(segment)[0].mean()\n",
    "                \n",
    "                final_score = (\n",
    "                    0.4 * duration_score + \n",
    "                    0.3 * min(1.0, energy / 0.1) + \n",
    "                    0.3 * spectral_centroid / 4000  \n",
    "                )\n",
    "            \n",
    "        elif phoneme in stops:\n",
    "            burst_dur = min(int(0.03 * sr), len(segment))\n",
    "            if burst_dur > 0:\n",
    "                burst_segment = segment[:burst_dur]\n",
    "                burst_energy = np.mean(burst_segment**2)\n",
    "                \n",
    "                burst_score = min(1.0, burst_energy / 0.2)  \n",
    "                \n",
    "                final_score = (\n",
    "                    0.4 * duration_score + \n",
    "                    0.4 * burst_score + \n",
    "                    0.2 * min(1.0, flux * 10)  \n",
    "                )\n",
    "            else:\n",
    "                final_score = duration_score\n",
    "                \n",
    "        elif phoneme in fricatives:\n",
    "            zero_crossing_rate = librosa.feature.zero_crossing_rate(segment)[0].mean()\n",
    "            spectral_flatness = librosa.feature.spectral_flatness(y=segment)[0].mean()\n",
    "            \n",
    "            zcr_score = min(1.0, zero_crossing_rate / 0.2) \n",
    "            \n",
    "            final_score = (\n",
    "                0.3 * duration_score + \n",
    "                0.4 * zcr_score + \n",
    "                0.3 * spectral_flatness\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "           \n",
    "            spectral_centroid = librosa.feature.spectral_centroid(y=segment, sr=sr)[0].mean()\n",
    "            zero_crossing_rate = librosa.feature.zero_crossing_rate(segment)[0].mean()\n",
    "            \n",
    "  \n",
    "            final_score = (\n",
    "                0.4 * duration_score + \n",
    "                0.3 * min(1.0, energy / 0.1) + \n",
    "                0.3 * (1.0 - min(1.0, abs(0.1 - zero_crossing_rate) / 0.1))\n",
    "            )\n",
    "        \n",
    "        alpha = 7.0  \n",
    "        beta = 0.5  \n",
    "        \n",
    "        # Apply sigmoid transformation to spread scores out more\n",
    "        final_score = 1.0 / (1.0 + np.exp(-alpha * (final_score - beta)))\n",
    "        \n",
    "        # Add small random component to prevent identical scores (0.01 max variance)\n",
    "        final_score += np.random.uniform(-0.01, 0.01)\n",
    "        \n",
    "        # Ensure score is within [0,1]\n",
    "        final_score = min(max(final_score, 0.0), 1.0)\n",
    "        \n",
    "        if final_score < 0.4:\n",
    "            grade = 'poor'\n",
    "        elif final_score < 0.55:\n",
    "            grade = 'borderline'\n",
    "        elif final_score < 0.7:\n",
    "            grade = 'good'\n",
    "        elif final_score < 0.85:\n",
    "            grade = 'very good'\n",
    "        else: \n",
    "            grade = 'excellent'\n",
    "            \n",
    "        tip = tips.get(ipa_map.get(phoneme, phoneme), '') if grade in ['poor', 'borderline', 'good'] else ''\n",
    "        \n",
    "        results.append({\n",
    "            'phoneme': phoneme,\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'score': float(final_score),\n",
    "            'grade': grade,\n",
    "            'tip': tip\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad3cc23",
   "metadata": {},
   "source": [
    "IPA and tips for providing more contextual feedback to the user. \n",
    "This let's the user know which sounds could be improved and how to do so.\n",
    "The IPA is a phonetic transcription system that provides a standardized way to represent the sounds of spoken language. It uses a set of symbols to represent each sound, allowing for precise and consistent representation of pronunciation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Feedback Generation ------------------\n",
    "\n",
    "# ARPABET to IPA mapping\n",
    "ipa_map = {\n",
    "    # Stops\n",
    "    \"P\":  \"p\",  \"B\":  \"b\",\n",
    "    \"T\":  \"t\",  \"D\":  \"d\",\n",
    "    \"K\":  \"k\",  \"G\":  \"g\",\n",
    "\n",
    "    # Affricates\n",
    "    \"CH\": \"tʃ\", \"JH\": \"dʒ\",\n",
    "\n",
    "    # Fricatives\n",
    "    \"F\":  \"f\",  \"V\":  \"v\",\n",
    "    \"TH\": \"θ\", \"DH\": \"ð\",\n",
    "    \"S\":  \"s\",  \"Z\":  \"z\",\n",
    "    \"SH\": \"ʃ\", \"ZH\": \"ʒ\",\n",
    "    \"HH\": \"h\",\n",
    "\n",
    "    # Nasals\n",
    "    \"M\":  \"m\",  \"N\":  \"n\",  \"NG\": \"ŋ\",\n",
    "\n",
    "    # Liquids & glides\n",
    "    \"L\":  \"l\",  \"R\":  \"ɹ\",\n",
    "    \"W\":  \"w\",  \"Y\":  \"j\",\n",
    "\n",
    "    # Vowels (monophthongs)\n",
    "    \"AA\": \"ɑ\",  \"AE\": \"æ\",\n",
    "    \"AH\": \"ʌ\",  \"AO\": \"ɔ\",\n",
    "    \"AW\": \"aʊ\", \"AY\": \"aɪ\",\n",
    "    \"EH\": \"ɛ\",  \"ER\": \"ɝ\",\n",
    "    \"EY\": \"eɪ\", \"IH\": \"ɪ\",\n",
    "    \"IY\": \"i\",  \"OW\": \"oʊ\",\n",
    "    \"OY\": \"ɔɪ\", \"UH\": \"ʊ\",\n",
    "    \"UW\": \"u\",  \"AX\": \"ə\",  # schwa\n",
    "\n",
    "    # Secondary stress or extra symbols\n",
    "    \"AXR\": \"ɚ\",  # r-colored schwa\n",
    "}\n",
    "\n",
    "# Learner-friendly pronunciation tips\n",
    "tips = {\n",
    "    # Stops\n",
    "    \"p\":  \"Close both lips then release with a small burst. Examples: 'pen', 'cup'. Common error: Aspirating too strongly—keep it light.\",\n",
    "    \"b\":  \"Close both lips and voice the release. Examples: 'bat', 'rub'. Common error: Voicing too softly—feel the vibration in your throat.\",\n",
    "    \"t\":  \"Place tongue tip behind your upper teeth ridge, then release. Examples: 'top', 'cat'. Common error: Using too much aspiration—release gently.\",\n",
    "    \"d\":  \"Place tongue tip behind the ridge and voice on release. Examples: 'dog', 'mad'. Common error: Dropping the tongue—keep contact until release.\",\n",
    "    \"k\":  \"Raise the back of your tongue to the soft palate, then release. Examples: 'key', 'back'. Common error: Not releasing fully—feel the puff of air.\",\n",
    "    \"g\":  \"Raise back of tongue, then voice on release. Examples: 'go', 'bag'. Common error: G-sound too soft—ensure vocal cords vibrate.\",\n",
    "\n",
    "    # Affricates\n",
    "    \"tʃ\": \"Start with /t/ then move into /ʃ/ in one smooth motion. Examples: 'chair', 'match'. Common error: Separating sounds—blend them.\",\n",
    "    \"dʒ\": \"Start with /d/ then move into /ʒ/. Examples: 'judge', 'edge'. Common error: Leaving out the /ʒ/—feel the vibration in your throat.\",\n",
    "\n",
    "    # Fricatives\n",
    "    \"f\":  \"Touch bottom lip to upper teeth and blow. Examples: 'fan', 'life'. Common error: Voicing it—keep it voiceless.\",\n",
    "    \"v\":  \"Touch bottom lip to upper teeth and voice. Examples: 'very', 'love'. Common error: Making it /w/—feel the vibration.\",\n",
    "    \"θ\": \"Place tongue between teeth and blow. Examples: 'think', 'bath'. Common error: Saying /f/—feel the air between teeth.\",\n",
    "    \"ð\": \"Place tongue between teeth and voice. Examples: 'this', 'breathe'. Common error: Saying /d/—look for tongue air.\",\n",
    "    \"s\":  \"Place tongue close to ridge and blow. Examples: 'see', 'bus'. Common error: Rounding lips—keep them spread.\",\n",
    "    \"z\":  \"Same as /s/ but voice. Examples: 'zoo', 'lazy'. Common error: Leaving out voice—feel the buzz.\",\n",
    "    \"ʃ\": \"Round lips and raise tongue middle. Examples: 'ship', 'nation'. Common error: Saying /s/—protrude lips.\",\n",
    "    \"ʒ\": \"Same as /ʃ/ but voice. Examples: 'measure', 'beige'. Common error: Devoicing—place fingers on throat.\",\n",
    "    \"h\":  \"Open mouth slightly and exhale. Examples: 'hat', 'ahead'. Common error: Too forceful—keep it breathy.\",\n",
    "\n",
    "    # Nasals\n",
    "    \"m\":  \"Close lips and voice through nose. Examples: 'man', 'home'. Common error: Oral release—keep velum lowered.\",\n",
    "    \"n\":  \"Tongue tip on ridge and voice through nose. Examples: 'no', 'ten'. Common error: Making it /d/—feel nasal buzz.\",\n",
    "    \"ŋ\": \"Back tongue on soft palate and voice. Examples: 'sing', 'ring'. Common error: Adding /g/—hold tongue position.\",\n",
    "\n",
    "    # Liquids & glides\n",
    "    \"l\":  \"Tongue tip on ridge and voice. Examples: 'light', 'feel'. Common error: Velarized /l/ everywhere—use light /l/ initially.\",\n",
    "    \"ɹ\": \"Curl tongue tip back without touching roof. Examples: 'red', 'sorry'. Common error: Rolling—keep it smooth.\",\n",
    "    \"w\":  \"Round lips and voice. Examples: 'water', 'away'. Common error: Not rounding—pucker your lips.\",\n",
    "    \"j\":  \"Raise tongue close to palate and glide. Examples: 'yes', 'beyond'. Common error: Too consonant—make it smooth.\",\n",
    "\n",
    "    # Vowels\n",
    "    \"i\":  \"Spread lips and raise tongue front-high. Examples: 'see', 'beat'. Common error: Relaxing tongue—keep it tense.\",\n",
    "    \"ɪ\": \"Slightly lower and relax from /i/. Examples: 'sit', 'hid'. Common error: Stretching—keep it short.\",\n",
    "    \"eɪ\": \"Start at /e/ then glide to /i/. Examples: 'say', 'they'. Common error: Not finishing glide—move to /i/.\",\n",
    "    \"ɛ\": \"Lower tongue from /ɪ/. Examples: 'bed', 'head'. Common error: Closing too much—open jaw more.\",\n",
    "    \"æ\": \"Open mouth wide, tongue low front. Examples: 'cat', 'hand'. Common error: Too narrow—drop jaw further.\",\n",
    "    \"ɑ\": \"Open mouth wide, tongue low back. Examples: 'father', 'spa'. Common error: Raising tongue—keep it flat.\",\n",
    "    \"ʌ\": \"Tongue mid, slightly back. Examples: 'cup', 'luck'. Common error: Confusing with /ə/—make it stronger.\",\n",
    "    \"ɔ\": \"Round lips, tongue mid-back. Examples: 'thought', 'law'. Common error: Using /ɑ/—round lips more.\",\n",
    "    \"oʊ\": \"Start /o/ then glide to /ʊ/. Examples: 'go', 'show'. Common error: Skipping glide—finish at /ʊ/.\",\n",
    "    \"ʊ\": \"Relaxed /u/. Examples: 'book', 'could'. Common error: Stretching to /u/—keep it short.\",\n",
    "    \"u\":  \"Round lips tightly, tongue high back. Examples: 'food', 'blue'. Common error: Not rounding—protrude lips.\",\n",
    "    \"ə\":  \"Neutral schwa. Examples: 'about', 'sofa'. Common error: Emphasizing—make it very brief.\",\n",
    "    \"ɝ\": \"R-colored schwa. Examples: 'her', 'bird'. Common error: Dropping /r/—curl tongue lightly.\",\n",
    "\n",
    "    # Diphthongs\n",
    "    \"aɪ\": \"Start /a/ then glide to /ɪ/. Examples: 'time', 'kite'. Common error: Too quick—complete the glide.\",\n",
    "    \"aʊ\": \"Start /a/ then glide to /ʊ/. Examples: 'house', 'now'. Common error: Missing lip rounding—round at end.\",\n",
    "    \"ɔɪ\": \"Start /ɔ/ then glide to /ɪ/. Examples: 'boy', 'toy'. Common error: Abrupt change—make it smooth.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec19a68",
   "metadata": {},
   "source": [
    "\n",
    "This section contains functions for analyzing pronunciation at the word level:\n",
    "\n",
    "extract_word_intervals: Extracts word timing information from TextGrid files, creating a list of word segments with start/end times.\n",
    "\n",
    "map_phonemes_to_words: Associates each phoneme with its corresponding word by checking if the phoneme falls within the word's time interval.\n",
    "\n",
    "compute_word_scores_and_feedback: Generates per-word feedback by averaging phoneme scores and identifying problematic sounds. For each word, it finds the lowest-scoring phonemes and provides targeted improvement tips using the IPA listed above. Later, they'll be able to find the IPA in the generated plot too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b235a82f",
   "metadata": {},
   "source": [
    "The functions utilize the TextGrid files which might look like this:\n",
    "\n",
    "```\n",
    "File type = \"ooTextFile\"\n",
    "Object class = \"TextGrid\"\n",
    "\n",
    "xmin = 0 \n",
    "xmax = 30.421312 \n",
    "tiers? <exists> \n",
    "size = 2 \n",
    "item []: \n",
    "    item [1]:\n",
    "        class = \"IntervalTier\" \n",
    "        name = \"words\" \n",
    "        xmin = 0 \n",
    "        xmax = 30.421312 \n",
    "        intervals: size = 34 \n",
    "        intervals [1]:\n",
    "            xmin = 0.0 \n",
    "            xmax = 3.09 \n",
    "            text = \"\" \n",
    "        intervals [2]:\n",
    "            xmin = 3.09 \n",
    "            xmax = 3.32 \n",
    "            text = \"a\" \n",
    "        intervals [3]:\n",
    "            xmin = 3.32 \n",
    "            xmax = 4.08 \n",
    "            text = \"girl\" \n",
    "        intervals [4]:\n",
    "            xmin = 4.08 \n",
    "            xmax = 4.91 \n",
    "            text = \"\" \n",
    "        intervals [5]:\n",
    "            xmin = 4.91 \n",
    "            xmax = 6.11 \n",
    "            text = \"planted\" \n",
    "        intervals [6]:\n",
    "            xmin = 6.11 \n",
    "            xmax = 7.18 \n",
    "            text = \"\" \n",
    "        intervals [7]:\n",
    "            xmin = 7.18 \n",
    "            xmax = 8.05 \n",
    "            text = \"a\" \n",
    "        intervals [8]:\n",
    "            xmin = 8.05 \n",
    "            xmax = 8.43 \n",
    "            text = \"\" \n",
    "        intervals [9]:\n",
    "            xmin = 8.43 \n",
    "            xmax = 9.83 \n",
    "            text = \"single\" \n",
    "        intervals [10]:\n",
    "            xmin = 9.83 \n",
    "            xmax = 10.05 \n",
    "            text = \"seed\" \n",
    "        intervals [11]:\n",
    "            xmin = 10.05 \n",
    "            xmax = 10.63 \n",
    "            text = \"in\" \n",
    "        intervals [12]:\n",
    "            xmin = 10.63 \n",
    "            xmax = 10.99 \n",
    "            text = \"\" \n",
    "        intervals [13]:\n",
    "            xmin = 10.99 \n",
    "            xmax = 11.65 \n",
    "            text = \"her\" \n",
    "        intervals [14]:\n",
    "            xmin = 11.65 \n",
    "            xmax = 12.31 \n",
    "            text = \"barren\" \n",
    "        intervals [15]:\n",
    "            xmin = 12.31 \n",
    "            xmax = 12.43 \n",
    "            text = \"\" \n",
    "        intervals [16]:\n",
    "            xmin = 12.43 \n",
    "            xmax = 13.02 \n",
    "            text = \"garden\" \n",
    "        intervals [17]:\n",
    "            xmin = 13.02 \n",
    "            xmax = 14.23 \n",
    "            text = \"\" \n",
    "        intervals [18]:\n",
    "            xmin = 14.23 \n",
    "            xmax = 14.85 \n",
    "            text = \"by\" \n",
    "        intervals [19]:\n",
    "            xmin = 14.85 \n",
    "            xmax = 16.34 \n",
    "            text = \"morning\" \n",
    "        intervals [20]:\n",
    "            xmin = 16.34 \n",
    "            xmax = 16.37 \n",
    "            text = \"\" \n",
    "        intervals [21]:\n",
    "            xmin = 16.37 \n",
    "            xmax = 17.55 \n",
    "            text = \"it\" \n",
    "        intervals [22]:\n",
    "            xmin = 17.55 \n",
    "            xmax = 17.79 \n",
    "            text = \"\" \n",
    "        intervals [23]:\n",
    "            xmin = 17.79 \n",
    "            xmax = 17.86 \n",
    "            text = \"had\" \n",
    "        intervals [24]:\n",
    "            xmin = 17.86 \n",
    "            xmax = 18.06 \n",
    "            text = \"grown\" \n",
    "        intervals [25]:\n",
    "            xmin = 18.06 \n",
    "            xmax = 18.27 \n",
    "            text = \"into\" \n",
    "        intervals [26]:\n",
    "            xmin = 18.27 \n",
    "            xmax = 18.35 \n",
    "            text = \"a\" \n",
    "        intervals [27]:\n",
    "            xmin = 18.35 \n",
    "            xmax = 18.93 \n",
    "            text = \"tree\" \n",
    "        intervals [28]:\n",
    "            xmin = 18.93 \n",
    "            xmax = 20.76 \n",
    "            text = \"\" \n",
    "        intervals [29]:\n",
    "            xmin = 20.76 \n",
    "            xmax = 21.18 \n",
    "            text = \"filled\" \n",
    "        intervals [30]:\n",
    "            xmin = 21.18 \n",
    "            xmax = 21.4 \n",
    "            text = \"with\" \n",
    "        intervals [31]:\n",
    "            xmin = 21.4 \n",
    "            xmax = 21.88 \n",
    "            text = \"golden\" \n",
    "        intervals [32]:\n",
    "            xmin = 21.88 \n",
    "            xmax = 21.95 \n",
    "            text = \"\" \n",
    "        intervals [33]:\n",
    "            xmin = 21.95 \n",
    "            xmax = 22.69 \n",
    "            text = \"fruit\" \n",
    "        intervals [34]:\n",
    "            xmin = 22.69 \n",
    "            xmax = 30.421312 \n",
    "            text = \"\" \n",
    "    item [2]:\n",
    "        class = \"IntervalTier\" \n",
    "        name = \"phones\" \n",
    "        xmin = 0 \n",
    "        xmax = 30.421312 \n",
    "        intervals: size = 89 \n",
    "        intervals [1]:\n",
    "            xmin = 0.0 \n",
    "            xmax = 3.09 \n",
    "            text = \"\" \n",
    "        intervals [2]:\n",
    "            xmin = 3.09 \n",
    "            xmax = 3.32 \n",
    "            text = \"AH0\" \n",
    "        intervals [3]:\n",
    "            xmin = 3.32 \n",
    "            xmax = 3.38 \n",
    "            text = \"G\" \n",
    "        intervals [4]:\n",
    "            xmin = 3.38 \n",
    "            xmax = 3.95 \n",
    "            text = \"ER1\" \n",
    "        intervals [5]:\n",
    "            xmin = 3.95 \n",
    "            xmax = 4.08 \n",
    "            text = \"L\" \n",
    "        intervals [6]:\n",
    "            xmin = 4.08 \n",
    "            xmax = 4.91 \n",
    "            text = \"\" \n",
    "        intervals [7]:\n",
    "            xmin = 4.91 \n",
    "            xmax = 4.94 \n",
    "            text = \"P\" \n",
    "        intervals [8]:\n",
    "            xmin = 4.94 \n",
    "            xmax = 4.97 \n",
    "            text = \"L\" \n",
    "        intervals [9]:\n",
    "            xmin = 4.97 \n",
    "            xmax = 5.71 \n",
    "            text = \"AE1\" \n",
    "        intervals [10]:\n",
    "            xmin = 5.71 \n",
    "            xmax = 5.74 \n",
    "            text = \"N\" \n",
    "        intervals [11]:\n",
    "            xmin = 5.74 \n",
    "            xmax = 6.04 \n",
    "            text = \"AH0\" \n",
    "        intervals [12]:\n",
    "            xmin = 6.04 \n",
    "            xmax = 6.11 \n",
    "            text = \"D\" \n",
    "        intervals [13]:\n",
    "            xmin = 6.11 \n",
    "            xmax = 7.18 \n",
    "            text = \"\" \n",
    "        intervals [14]:\n",
    "            xmin = 7.18 \n",
    "            xmax = 8.05 \n",
    "            text = \"AH0\" \n",
    "        intervals [15]:\n",
    "            xmin = 8.05 \n",
    "            xmax = 8.43 \n",
    "            text = \"\" \n",
    "        intervals [16]:\n",
    "            xmin = 8.43 \n",
    "            xmax = 9.34 \n",
    "            text = \"S\" \n",
    "        intervals [17]:\n",
    "            xmin = 9.34 \n",
    "            xmax = 9.59 \n",
    "            text = \"IH1\" \n",
    "        intervals [18]:\n",
    "            xmin = 9.59 \n",
    "            xmax = 9.62 \n",
    "            text = \"NG\" \n",
    "        intervals [19]:\n",
    "            xmin = 9.62 \n",
    "            xmax = 9.65 \n",
    "            text = \"G\" \n",
    "        intervals [20]:\n",
    "            xmin = 9.65 \n",
    "            xmax = 9.77 \n",
    "            text = \"AH0\" \n",
    "        intervals [21]:\n",
    "            xmin = 9.77 \n",
    "            xmax = 9.83 \n",
    "            text = \"L\" \n",
    "        intervals [22]:\n",
    "            xmin = 9.83 \n",
    "            xmax = 9.99 \n",
    "            text = \"S\" \n",
    "        intervals [23]:\n",
    "            xmin = 9.99 \n",
    "            xmax = 10.02 \n",
    "            text = \"IY1\" \n",
    "        intervals [24]:\n",
    "            xmin = 10.02 \n",
    "            xmax = 10.05 \n",
    "            text = \"D\" \n",
    "        intervals [25]:\n",
    "            xmin = 10.05 \n",
    "            xmax = 10.59 \n",
    "            text = \"IH1\" \n",
    "        intervals [26]:\n",
    "            xmin = 10.59 \n",
    "            xmax = 10.63 \n",
    "            text = \"N\" \n",
    "        intervals [27]:\n",
    "            xmin = 10.63 \n",
    "            xmax = 10.99 \n",
    "            text = \"\" \n",
    "        intervals [28]:\n",
    "            xmin = 10.99 \n",
    "            xmax = 11.02 \n",
    "            text = \"HH\" \n",
    "        intervals [29]:\n",
    "            xmin = 11.02 \n",
    "            xmax = 11.65 \n",
    "            text = \"ER1\" \n",
    "        intervals [30]:\n",
    "            xmin = 11.65 \n",
    "            xmax = 11.75 \n",
    "            text = \"B\" \n",
    "        intervals [31]:\n",
    "            xmin = 11.75 \n",
    "            xmax = 11.87 \n",
    "            text = \"EH1\" \n",
    "        intervals [32]:\n",
    "            xmin = 11.87 \n",
    "            xmax = 11.99 \n",
    "            text = \"R\" \n",
    "        intervals [33]:\n",
    "            xmin = 11.99 \n",
    "            xmax = 12.11 \n",
    "            text = \"AH0\" \n",
    "        intervals [34]:\n",
    "            xmin = 12.11 \n",
    "            xmax = 12.31 \n",
    "            text = \"N\" \n",
    "        intervals [35]:\n",
    "            xmin = 12.31 \n",
    "            xmax = 12.43 \n",
    "            text = \"\" \n",
    "        intervals [36]:\n",
    "            xmin = 12.43 \n",
    "            xmax = 12.48 \n",
    "            text = \"G\" \n",
    "        intervals [37]:\n",
    "            xmin = 12.48 \n",
    "            xmax = 12.56 \n",
    "            text = \"AA1\" \n",
    "        intervals [38]:\n",
    "            xmin = 12.56 \n",
    "            xmax = 12.7 \n",
    "            text = \"R\" \n",
    "        intervals [39]:\n",
    "            xmin = 12.7 \n",
    "            xmax = 12.76 \n",
    "            text = \"D\" \n",
    "        intervals [40]:\n",
    "            xmin = 12.76 \n",
    "            xmax = 12.94 \n",
    "            text = \"AH0\" \n",
    "        intervals [41]:\n",
    "            xmin = 12.94 \n",
    "            xmax = 13.02 \n",
    "            text = \"N\" \n",
    "        intervals [42]:\n",
    "            xmin = 13.02 \n",
    "            xmax = 14.23 \n",
    "            text = \"\" \n",
    "        intervals [43]:\n",
    "            xmin = 14.23 \n",
    "            xmax = 14.39 \n",
    "            text = \"B\" \n",
    "        intervals [44]:\n",
    "            xmin = 14.39 \n",
    "            xmax = 14.85 \n",
    "            text = \"AY1\" \n",
    "        intervals [45]:\n",
    "            xmin = 14.85 \n",
    "            xmax = 14.88 \n",
    "            text = \"M\" \n",
    "        intervals [46]:\n",
    "            xmin = 14.88 \n",
    "            xmax = 15.51 \n",
    "            text = \"AO1\" \n",
    "        intervals [47]:\n",
    "            xmin = 15.51 \n",
    "            xmax = 15.67 \n",
    "            text = \"R\" \n",
    "        intervals [48]:\n",
    "            xmin = 15.67 \n",
    "            xmax = 15.76 \n",
    "            text = \"N\" \n",
    "        intervals [49]:\n",
    "            xmin = 15.76 \n",
    "            xmax = 16.09 \n",
    "            text = \"IH0\" \n",
    "        intervals [50]:\n",
    "            xmin = 16.09 \n",
    "            xmax = 16.34 \n",
    "            text = \"NG\" \n",
    "        intervals [51]:\n",
    "            xmin = 16.34 \n",
    "            xmax = 16.37 \n",
    "            text = \"\" \n",
    "        intervals [52]:\n",
    "            xmin = 16.37 \n",
    "            xmax = 17.52 \n",
    "            text = \"IH0\" \n",
    "        intervals [53]:\n",
    "            xmin = 17.52 \n",
    "            xmax = 17.55 \n",
    "            text = \"T\" \n",
    "        intervals [54]:\n",
    "            xmin = 17.55 \n",
    "            xmax = 17.79 \n",
    "            text = \"\" \n",
    "        intervals [55]:\n",
    "            xmin = 17.79 \n",
    "            xmax = 17.82 \n",
    "            text = \"HH\" \n",
    "        intervals [56]:\n",
    "            xmin = 17.82 \n",
    "            xmax = 17.83 \n",
    "            text = \"AE1\" \n",
    "        intervals [57]:\n",
    "            xmin = 17.83 \n",
    "            xmax = 17.86 \n",
    "            text = \"D\" \n",
    "        intervals [58]:\n",
    "            xmin = 17.86 \n",
    "            xmax = 17.89 \n",
    "            text = \"G\" \n",
    "        intervals [59]:\n",
    "            xmin = 17.89 \n",
    "            xmax = 17.97 \n",
    "            text = \"R\" \n",
    "        intervals [60]:\n",
    "            xmin = 17.97 \n",
    "            xmax = 18.01 \n",
    "            text = \"OW1\" \n",
    "        intervals [61]:\n",
    "            xmin = 18.01 \n",
    "            xmax = 18.06 \n",
    "            text = \"N\" \n",
    "        intervals [62]:\n",
    "            xmin = 18.06 \n",
    "            xmax = 18.11 \n",
    "            text = \"IH0\" \n",
    "        intervals [63]:\n",
    "            xmin = 18.11 \n",
    "            xmax = 18.17 \n",
    "            text = \"N\" \n",
    "        intervals [64]:\n",
    "            xmin = 18.17 \n",
    "            xmax = 18.21 \n",
    "            text = \"T\" \n",
    "        intervals [65]:\n",
    "            xmin = 18.21 \n",
    "            xmax = 18.27 \n",
    "            text = \"AH0\" \n",
    "        intervals [66]:\n",
    "            xmin = 18.27 \n",
    "            xmax = 18.35 \n",
    "            text = \"AH0\" \n",
    "        intervals [67]:\n",
    "            xmin = 18.35 \n",
    "            xmax = 18.38 \n",
    "            text = \"T\" \n",
    "        intervals [68]:\n",
    "            xmin = 18.38 \n",
    "            xmax = 18.41 \n",
    "            text = \"R\" \n",
    "        intervals [69]:\n",
    "            xmin = 18.41 \n",
    "            xmax = 18.93 \n",
    "            text = \"IY1\" \n",
    "        intervals [70]:\n",
    "            xmin = 18.93 \n",
    "            xmax = 20.76 \n",
    "            text = \"\" \n",
    "        intervals [71]:\n",
    "            xmin = 20.76 \n",
    "            xmax = 20.79 \n",
    "            text = \"F\" \n",
    "        intervals [72]:\n",
    "            xmin = 20.79 \n",
    "            xmax = 20.91 \n",
    "            text = \"IH1\" \n",
    "        intervals [73]:\n",
    "            xmin = 20.91 \n",
    "            xmax = 20.95 \n",
    "            text = \"L\" \n",
    "        intervals [74]:\n",
    "            xmin = 20.95 \n",
    "            xmax = 21.18 \n",
    "            text = \"D\" \n",
    "        intervals [75]:\n",
    "            xmin = 21.18 \n",
    "            xmax = 21.21 \n",
    "            text = \"W\" \n",
    "        intervals [76]:\n",
    "            xmin = 21.21 \n",
    "            xmax = 21.24 \n",
    "            text = \"IH0\" \n",
    "        intervals [77]:\n",
    "            xmin = 21.24 \n",
    "            xmax = 21.4 \n",
    "            text = \"DH\" \n",
    "        intervals [78]:\n",
    "            xmin = 21.4 \n",
    "            xmax = 21.43 \n",
    "            text = \"G\" \n",
    "        intervals [79]:\n",
    "            xmin = 21.43 \n",
    "            xmax = 21.56 \n",
    "            text = \"OW1\" \n",
    "        intervals [80]:\n",
    "            xmin = 21.56 \n",
    "            xmax = 21.79 \n",
    "            text = \"L\" \n",
    "        intervals [81]:\n",
    "            xmin = 21.79 \n",
    "            xmax = 21.82 \n",
    "            text = \"D\" \n",
    "        intervals [82]:\n",
    "            xmin = 21.82 \n",
    "            xmax = 21.85 \n",
    "            text = \"AH0\" \n",
    "        intervals [83]:\n",
    "            xmin = 21.85 \n",
    "            xmax = 21.88 \n",
    "            text = \"N\" \n",
    "        intervals [84]:\n",
    "            xmin = 21.88 \n",
    "            xmax = 21.95 \n",
    "            text = \"\" \n",
    "        intervals [85]:\n",
    "            xmin = 21.95 \n",
    "            xmax = 22.37 \n",
    "            text = \"F\" \n",
    "        intervals [86]:\n",
    "            xmin = 22.37 \n",
    "            xmax = 22.42 \n",
    "            text = \"R\" \n",
    "        intervals [87]:\n",
    "            xmin = 22.42 \n",
    "            xmax = 22.65 \n",
    "            text = \"UW1\" \n",
    "        intervals [88]:\n",
    "            xmin = 22.65 \n",
    "            xmax = 22.69 \n",
    "            text = \"T\" \n",
    "        intervals [89]:\n",
    "            xmin = 22.69 \n",
    "            xmax = 30.421312 \n",
    "            text = \"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_word_intervals(tg_path):\n",
    "    tg = TextGrid()\n",
    "    tg.read(tg_path)\n",
    "    \n",
    "    word_tier = next((t for t in tg.tiers if t.name.lower() in ('words', 'word')), None)\n",
    "    if word_tier is None:\n",
    "        raise ValueError(\"No 'words' tier found in TextGrid.\")\n",
    "    \n",
    "    words = [\n",
    "        {'word': iv.mark.strip(), 'start': iv.minTime, 'end': iv.maxTime}\n",
    "        for iv in word_tier.intervals if iv.mark.strip()\n",
    "    ]\n",
    "    return words\n",
    "\n",
    "\n",
    "def map_phonemes_to_words(phoneme_results, word_intervals):\n",
    "    word_map = {w['word']: [] for w in word_intervals}\n",
    "    for phon in phoneme_results:\n",
    "        mid = (phon['start'] + phon['end']) / 2.0\n",
    "        for w in word_intervals:\n",
    "            if w['start'] <= mid <= w['end']:\n",
    "                word_map[w['word']].append(phon)\n",
    "                break\n",
    "    return word_map\n",
    "\n",
    "\n",
    "def compute_word_scores_and_feedback(word_map, ipa_map, tips):\n",
    "    feedback_list = []\n",
    "    for word, phons in word_map.items():\n",
    "        if not phons:\n",
    "            continue\n",
    "        scores = [p['score'] for p in phons]\n",
    "        avg_score = float(np.mean(scores))\n",
    "        worst = sorted(phons, key=lambda p: p['score'])[:2]\n",
    "        sentences = []\n",
    "        for p in worst:\n",
    "            arp = p['phoneme']\n",
    "            ipa = ipa_map.get(arp, arp)\n",
    "            tip = tips.get(ipa, '')\n",
    "            sentences.append(\n",
    "                f\"Your /{ipa}/ sound in '{word}' scored {p['score']:.2f}. {tip}\"\n",
    "            )\n",
    "        feedback_list.append({\n",
    "            'word': word,\n",
    "            'avg_score': avg_score,\n",
    "            'feedback': sentences\n",
    "        })\n",
    "    feedback_list.sort(key=lambda x: x['avg_score'])\n",
    "    return feedback_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307ed28",
   "metadata": {},
   "source": [
    "An easy to understand plot that's displated to the user in the front end. It consists of color graded pillars for each phenome they've pronounced for the entire sentence. The phenomes are written on top of the pillars, so the user can review the expected vs. actual pronunciation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Plots -------------------\n",
    "\n",
    "def create_phoneme_timeline(results, base_dir):\n",
    "    \"\"\"Create a color-coded timeline visualization of phoneme scores\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    colors = {\n",
    "        'poor': 'red',\n",
    "        'borderline': 'orange',\n",
    "        'good': 'yellow',\n",
    "        'very good': 'lightgreen',\n",
    "        'excellent': 'green'\n",
    "    }\n",
    "    \n",
    "    for i, phoneme in enumerate(results):\n",
    "        plt.barh(0, phoneme['end'] - phoneme['start'], left=phoneme['start'], \n",
    "                height=0.5, color=colors[phoneme['grade']], alpha=0.7)\n",
    "        \n",
    "        text_x = phoneme['start'] + (phoneme['end'] - phoneme['start'])/2\n",
    "        plt.text(text_x, 0, phoneme['phoneme'], ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    handles = [plt.Rectangle((0,0),1,1, color=colors[grade]) for grade in colors]\n",
    "    plt.legend(handles, colors.keys(), loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=4)\n",
    "    \n",
    "    plt.yticks([])\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.title('Pronunciation Quality Timeline')\n",
    "    \n",
    "    # Save the figure\n",
    "    timeline_path = os.path.join(os.path.dirname(base_dir), \"phoneme_timeline.png\")\n",
    "    plt.savefig(timeline_path)\n",
    "    plt.close()\n",
    "    \n",
    "    return timeline_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09240da",
   "metadata": {},
   "source": [
    "Set up code for the pretrained facebook model (Wav2Vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_pretrained_model():\n",
    "    print(\"Initializing pretrained pronunciation model...\")\n",
    "    \n",
    "    model_name = \"facebook/wav2vec2-large-960h-lv60-self\" \n",
    "    \n",
    "    try:\n",
    "        processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "        model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "        print(f\"Successfully loaded {model_name}\")\n",
    "        return processor, model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pretrained model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "wav2vec_processor = None\n",
    "wav2vec_model = None\n",
    "\n",
    "def init_models():\n",
    "    global wav2vec_processor, wav2vec_model\n",
    "    if wav2vec_processor is None or wav2vec_model is None:\n",
    "        wav2vec_processor, wav2vec_model = initialize_pretrained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad55f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_score_phonemes(audio_path, phoneme_intervals):\n",
    "    \"\"\"\n",
    "    Enhanced scoring that combines rule-based features with pretrained model confidence\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_path: Path to the audio file\n",
    "    - phoneme_intervals: List of phoneme intervals from MFA\n",
    "    - reference_intervals: Optional reference intervals\n",
    "    \n",
    "    Returns:\n",
    "    - List of phoneme scores with enhanced scoring\n",
    "    \"\"\"\n",
    "    # Initialize models if needed\n",
    "    init_models()\n",
    "    \n",
    "    # First get the base scores using your existing function\n",
    "    base_scores = score_phonemes_with_mfa(audio_path, phoneme_intervals)\n",
    "    \n",
    "    # If model loading failed, return base scores\n",
    "    if wav2vec_processor is None or wav2vec_model is None:\n",
    "        print(\"Warning: Using only rule-based scoring as pretrained model failed to load\")\n",
    "        return base_scores\n",
    "    \n",
    "    try:\n",
    "        # Load and resample audio\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "        # Resample to 16kHz if needed\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "        \n",
    "        # Convert to mono if needed\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Process through wav2vec\n",
    "        with torch.no_grad():\n",
    "            # Get model's features\n",
    "            inputs = wav2vec_processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                # Get logits (pre-softmax outputs)\n",
    "                outputs = wav2vec_model(**inputs)\n",
    "                logits = outputs.logits\n",
    "                \n",
    "            # Get predicted probabilities\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Get confidence scores for each timeframe\n",
    "            confidences = torch.max(probs, dim=-1)[0]\n",
    "            \n",
    "            # Convert to numpy\n",
    "            confidence_values = confidences.squeeze().numpy()\n",
    "            \n",
    "            # Calculate frame rate for alignment\n",
    "            frames_per_second = len(confidence_values) / (waveform.shape[1] / 16000)\n",
    "        \n",
    "        # Enhanced scores with pretrained model confidence\n",
    "        enhanced_results = []\n",
    "        for i, phoneme in enumerate(base_scores):\n",
    "            # Extract start and end frame indices\n",
    "            frame_start = int(phoneme['start'] * frames_per_second)\n",
    "            frame_end = int(phoneme['end'] * frames_per_second)\n",
    "            \n",
    "            # Ensure frame indices are valid\n",
    "            frame_start = max(0, frame_start)\n",
    "            frame_end = min(len(confidence_values) - 1, frame_end)\n",
    "            \n",
    "            if frame_start < frame_end:\n",
    "                # Calculate mean confidence for this phoneme\n",
    "                phoneme_confidence = np.mean(confidence_values[frame_start:frame_end])\n",
    "                \n",
    "                # Combine rule-based score with model confidence\n",
    "                # Weight: 60% rule-based, 40% model confidence\n",
    "                enhanced_score = 0.4 * phoneme['score'] + 0.6 * phoneme_confidence\n",
    "                \n",
    "                # Ensure score is in [0,1] range\n",
    "                enhanced_score = min(max(enhanced_score, 0.0), 1.0)\n",
    "                \n",
    "                # Update grade based on enhanced score\n",
    "                if enhanced_score < 0.4:\n",
    "                    grade = 'poor'\n",
    "                elif enhanced_score < 0.55:  # 0.4 + 0.15\n",
    "                    grade = 'borderline'\n",
    "                elif enhanced_score < 0.7:   # 0.55 + 0.15\n",
    "                    grade = 'good'\n",
    "                elif enhanced_score < 0.85:  # 0.7 + 0.15\n",
    "                    grade = 'very good'\n",
    "                else:\n",
    "                    grade = 'excellent'\n",
    "                \n",
    "                # Create enhanced result\n",
    "                enhanced_result = phoneme.copy()\n",
    "                enhanced_result['score'] = float(enhanced_score)\n",
    "                enhanced_result['grade'] = grade\n",
    "                enhanced_result['confidence'] = float(phoneme_confidence)\n",
    "            else:\n",
    "                enhanced_result = phoneme.copy()\n",
    "            \n",
    "            enhanced_results.append(enhanced_result)\n",
    "        \n",
    "        return enhanced_results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in enhanced scoring: {e}\")\n",
    "        return base_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfdc08",
   "metadata": {},
   "source": [
    "Final function tying all the previous functions together. It takes the audio file, the TextGrid file, and the dictionary as inputs. It runs the Montreal Forced Aligner to align the audio with the transcript, extracts phoneme intervals, and computes scores and feedback for each phoneme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_audio_enhanced(wav_path: str, transcript: str, base_dir = None):\n",
    "    \"\"\"Enhanced version of process_audio that uses the pretrained model for scoring\"\"\"\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "    tg_path = run_mfa_alignment(wav_path, transcript)\n",
    "    tg = TextGrid()\n",
    "    tg.read(tg_path)\n",
    "\n",
    "    phoneme_tier = next((t for t in tg.tiers if t.name.lower() == 'phones'), None)\n",
    "\n",
    "    # Extract phoneme intervals\n",
    "    phoneme_intervals = [\n",
    "        {'phoneme': interval.mark.strip(), 'start': interval.minTime, 'end': interval.maxTime}\n",
    "        for interval in phoneme_tier.intervals if interval.mark.strip()\n",
    "    ]\n",
    "\n",
    "    \n",
    "    results = enhanced_score_phonemes(wav_path, phoneme_intervals)\n",
    "    \n",
    "    word_interval = extract_word_intervals(tg_path)\n",
    "    word_map = map_phonemes_to_words(results, word_interval)\n",
    "    word_feedback = compute_word_scores_and_feedback(word_map, ipa_map, tips)\n",
    "    \n",
    "    if base_dir is None:\n",
    "        base_dir = os.path.dirname(wav_path)\n",
    "    \n",
    "    timeline_path = create_phoneme_timeline(results, tg_path)\n",
    "    \n",
    "    return {\n",
    "        'phoneme_feedback': results,\n",
    "        'phoneme_timeline': timeline_path,\n",
    "        'word_feedback': word_feedback,\n",
    "        'transcript': transcript,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d3254d",
   "metadata": {},
   "source": [
    "REST API USING FLASK TO SERVE THE FRONT END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "@app.route('/score', methods=['POST'])\n",
    "def score_route():\n",
    "    try:\n",
    "        # Check for uploaded audio file\n",
    "        if 'audio' not in request.files:\n",
    "            return jsonify({\"error\": \"Audio file is required\"}), 400\n",
    "\n",
    "        # Get the uploaded audio file and transcript text\n",
    "        audio_file = request.files['audio']\n",
    "        transcript = request.form.get('transcript')\n",
    "        use_enhanced = request.form.get('use_enhanced', 'true').lower() == 'true'\n",
    "\n",
    "        if not transcript:\n",
    "            return jsonify({\"error\": \"Transcript text is required\"}), 400\n",
    "\n",
    "        print(f\"Received audio file: {audio_file.filename}\")\n",
    "\n",
    "        # Save the uploaded audio file to a temporary directory\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        audio_path = os.path.join(temp_dir, audio_file.filename)\n",
    "        audio_file.save(audio_path)\n",
    "\n",
    "        # Convert MP3 to WAV if necessary\n",
    "        if audio_path.lower().endswith('.mp3'):\n",
    "            print(\"Converting MP3 to WAV...\")\n",
    "            wav_path = convert_mp3_to_wav(audio_path, audio_path.replace('.mp3', '.wav'))\n",
    "            print(f\"Converted wav_path: {wav_path}\")\n",
    "        elif audio_path.lower().endswith('.webm'):\n",
    "            print(\"Converting WEBM to WAV...\")\n",
    "            wav_path = convert_webm_to_wav(audio_path, audio_path.replace('.webm', '.wav'))\n",
    "            print(f\"Converted wav_path: {wav_path}\")\n",
    "        else:\n",
    "            wav_path = audio_path\n",
    "\n",
    "        # Save the transcript text to a temporary file\n",
    "        transcript_path = os.path.join(temp_dir, \"transcript.txt\")\n",
    "        with open(transcript_path, \"w\") as f:\n",
    "            # f.write(transcript) ensure transcript is one long strings, if there's newlines and more than one whitespace anywhere, tuncate to one long string whith a maximum one character whitespace whic his a normal space\n",
    "            f.write(' '.join(transcript.split()))\n",
    "            \n",
    "            \n",
    "        print(f\"Expected content of audio file:\" + ' '.join(transcript.split()))\n",
    "\n",
    "        # Log before processing audio\n",
    "        print(\"Processing audio...\")\n",
    "\n",
    "        # Choose processing method based on flag\n",
    "        if use_enhanced:\n",
    "            res = process_audio_enhanced(wav_path, transcript_path, base_dir=None)\n",
    "\n",
    "        # Log the result\n",
    "        print(\"Processing complete.\")\n",
    "\n",
    "        # Clean up temporary files\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "        # Return the result\n",
    "        return jsonify(res), 200\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the error\n",
    "        print(\"Error occurred:\", str(e))\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/get-timeline', methods=['GET'])\n",
    "def get_timeline():\n",
    "    \"\"\"Serve the phoneme timeline image based on the provided relative path.\"\"\"\n",
    "    # Get the relative path from the query parameter\n",
    "    relative_path = request.args.get('path')\n",
    "    \n",
    "    if not relative_path:\n",
    "        return jsonify({\"error\": \"No path provided\"}), 400\n",
    "\n",
    "    # Construct the absolute path\n",
    "    absolute_path = os.path.abspath(relative_path)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(absolute_path):\n",
    "        return send_file(absolute_path, mimetype='image/png')\n",
    "    else:\n",
    "        return jsonify({\"error\": f\"File not found: {relative_path}\"}), 404\n",
    "    \n",
    "\"\"\"\n",
    "timeline URL request: localhost:5000/get-timeline?path=phoneme_timeline.png\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    init_models()\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
